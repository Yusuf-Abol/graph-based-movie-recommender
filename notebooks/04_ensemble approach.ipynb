{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "085cf724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch_scatter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b4aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path(\"C://Users//DELL//Desktop//the-year-25-26//scalable-graph-based-movie-recommender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137d8612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1225734739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1225865086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1225733503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1225735204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1225735119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1        1     4.0  1225734739\n",
       "1       1      110     4.0  1225865086\n",
       "2       1      158     4.0  1225733503\n",
       "3       1      260     4.5  1225735204\n",
       "4       1      356     5.0  1225735119"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(project_root / 'data' / 'processed' / 'ratings_gnn.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b3b03bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(project_root / 'data' / 'processed' / 'movies_gnn.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "089715dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>3863</td>\n",
       "      <td>atmospheric</td>\n",
       "      <td>1476691609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302</td>\n",
       "      <td>3863</td>\n",
       "      <td>beautiful cinematography</td>\n",
       "      <td>1476691614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "      <td>3863</td>\n",
       "      <td>stylized</td>\n",
       "      <td>1476691602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>302</td>\n",
       "      <td>4226</td>\n",
       "      <td>great ending</td>\n",
       "      <td>1476691644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302</td>\n",
       "      <td>4226</td>\n",
       "      <td>psychological</td>\n",
       "      <td>1476691635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId                       tag   timestamp\n",
       "0     302     3863               atmospheric  1476691609\n",
       "1     302     3863  beautiful cinematography  1476691614\n",
       "2     302     3863                  stylized  1476691602\n",
       "3     302     4226              great ending  1476691644\n",
       "4     302     4226             psychological  1476691635"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = pd.read_csv(project_root / 'data' / 'processed' / 'tags_gnn.csv')\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05b54cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>tagId</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.07000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.12300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  tagId  relevance\n",
       "0        1      1    0.03200\n",
       "1        1      2    0.02225\n",
       "2        1      3    0.07000\n",
       "3        1      4    0.05900\n",
       "4        1      5    0.12300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome_scores= pd.read_csv(project_root / 'data' / 'processed' / 'genome_scores_gnn.csv')\n",
    "genome_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f71edd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tagId</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>007 (series)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1920s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1930s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tagId           tag\n",
       "0      1           007\n",
       "1      2  007 (series)\n",
       "2      3  18th century\n",
       "3      4         1920s\n",
       "4      5         1930s"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome_tags= pd.read_csv(project_root / 'data' / 'processed' / 'genome_tags_gnn.csv')\n",
    "genome_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5234ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = ratings['userId'].unique()\n",
    "movie_ids = ratings['movieId'].unique()\n",
    "num_users = len(user_ids)\n",
    "num_movies = len(movie_ids)\n",
    "\n",
    "# Map original IDs to continuous indices\n",
    "user_mapping = {id: idx for idx, id in enumerate(user_ids)}\n",
    "movie_mapping = {id: idx for idx, id in enumerate(movie_ids)}\n",
    "\n",
    "ratings['user_idx'] = ratings['userId'].map(user_mapping)\n",
    "ratings['movie_idx'] = ratings['movieId'].map(movie_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "031313bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.     , 0.032  , 0.02225, ..., 0.033  , 0.077  , 0.01825],\n",
       "       [0.     , 0.0525 , 0.031  , ..., 0.08975, 0.0895 , 0.0235 ],\n",
       "       [0.     , 0.03275, 0.04125, ..., 0.008  , 0.10025, 0.01475],\n",
       "       ...,\n",
       "       [0.     , 0.02975, 0.03075, ..., 0.0065 , 0.106  , 0.0165 ],\n",
       "       [0.     , 0.03125, 0.03425, ..., 0.00575, 0.087  , 0.01175],\n",
       "       [0.     , 0.04125, 0.044  , ..., 0.00625, 0.1225 , 0.01775]],\n",
       "      shape=(5979, 1129))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter content data\n",
    "tags_filtered = tags[tags['movieId'].isin(movie_ids)]\n",
    "genome_scores_filtered = genome_scores[genome_scores['movieId'].isin(movie_ids)]\n",
    "\n",
    "# Create content features (reduce genome dimensionality)\n",
    "from scipy.sparse import csc_matrix\n",
    "genome_matrix = csc_matrix(\n",
    "    (genome_scores_filtered['relevance'].values,\n",
    "     (genome_scores_filtered['movieId'].map(movie_mapping).values,\n",
    "      genome_scores_filtered['tagId'].values)),\n",
    "    shape=(num_movies, genome_tags['tagId'].max() + 1)\n",
    ").toarray()\n",
    "\n",
    "genome_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f15b9c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.9723e-01,  1.0766e+00,  3.0914e+00,  ..., -3.2717e-02,\n",
       "          4.9399e-02, -4.4391e-01],\n",
       "        [ 3.4215e+00,  2.6226e+00,  3.4195e+00,  ..., -7.1543e-02,\n",
       "          1.1128e-01, -2.6499e-01],\n",
       "        [-2.0368e+00, -5.4134e-01,  1.1547e+00,  ...,  3.4155e-01,\n",
       "         -7.3131e-03,  1.0712e-01],\n",
       "        ...,\n",
       "        [ 2.4176e-01, -1.2308e+00, -5.9882e-01,  ...,  5.6452e-02,\n",
       "         -5.8670e-02, -8.3411e-02],\n",
       "        [-1.8002e+00, -9.2147e-01,  1.5571e-02,  ..., -1.3413e-01,\n",
       "          1.8907e-03, -8.8710e-02],\n",
       "        [-1.3067e+00, -4.0330e-01, -9.0030e-01,  ...,  1.6591e-01,\n",
       "         -8.4876e-02, -1.8701e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce genome features to 64 dimensions\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=64)\n",
    "genome_features_reduced = pca.fit_transform(genome_matrix)\n",
    "movie_content_features = torch.tensor(genome_features_reduced, dtype=torch.float)\n",
    "movie_content_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "689fe9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2530,  0.1174,  0.8302,  ..., -0.5667, -0.1320, -1.1239],\n",
       "        [-0.8906,  0.2787,  0.4533,  ...,  0.3281, -0.0848, -1.5943],\n",
       "        [ 0.5214,  0.4572, -1.2895,  ..., -0.9175,  0.3495, -0.5758],\n",
       "        ...,\n",
       "        [-0.4667, -0.0059, -0.1572,  ..., -0.9803,  1.1263, -0.7283],\n",
       "        [ 1.1180,  1.3720,  0.2362,  ...,  0.4294, -1.0032, -0.0793],\n",
       "        [-0.7784, -0.9990,  0.9899,  ...,  1.4126,  1.9528, -1.5964]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create features for both users and movies with same dimension\n",
    "base_features = torch.randn(num_users + num_movies, 64)\n",
    "user_features = base_features[:num_users]  # 64-dim users\n",
    "movie_features = base_features[num_users:] + 0.1 * movie_content_features  # 64-dim movies with content bias\n",
    "\n",
    "# Combine features (same dimension for both)\n",
    "x = torch.cat([user_features, movie_features], dim=0)  # [num_users + num_movies, 64]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35ef2476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[20979, 64], edge_index=[2, 5219794], edge_attr=[5219794])\n"
     ]
    }
   ],
   "source": [
    "# Create a bipartite graph\n",
    "user_idx = ratings['user_idx'].values\n",
    "movie_idx = ratings['movie_idx'].values + num_users\n",
    "\n",
    "edge_index_np = np.column_stack([\n",
    "    np.concatenate([user_idx, movie_idx]),\n",
    "    np.concatenate([movie_idx, user_idx])\n",
    "]).T\n",
    "\n",
    "edge_index = torch.from_numpy(edge_index_np)\n",
    "ratings_tensor = torch.tensor(ratings['rating'].values, dtype=torch.float)\n",
    "edge_attr = torch.cat([ratings_tensor, ratings_tensor])\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88e77eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6abea3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize\n",
    "import torch_scatter\n",
    "from torch_geometric.nn import GCNConv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "354fd2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MATRIX FACTORIZATION MODEL\n",
    "\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embed_dim=64, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.user_embed = nn.Embedding(num_users, embed_dim)\n",
    "        self.movie_embed = nn.Embedding(num_movies, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        nn.init.normal_(self.user_embed.weight, std=0.1)\n",
    "        nn.init.normal_(self.movie_embed.weight, std=0.1)\n",
    "        \n",
    "    def forward(self, user_idx, movie_idx):\n",
    "        user_vec = self.dropout(self.user_embed(user_idx)) \n",
    "        movie_vec = self.dropout(self.movie_embed(movie_idx))\n",
    "        return (user_vec * movie_vec).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97399499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LIGHTGCN MODEL\n",
    "\n",
    "class LightGCN_Rating(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embed_dim=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # User and movie embeddings\n",
    "        self.user_embed = nn.Embedding(num_users, embed_dim)\n",
    "        self.movie_embed = nn.Embedding(num_movies, embed_dim)\n",
    "        \n",
    "        # Learnable layer weights (LightGCN paper)\n",
    "        self.layer_weights = nn.Parameter(torch.ones(num_layers + 1) / (num_layers + 1))\n",
    "        \n",
    "        # Rating prediction head\n",
    "        self.rating_predictor = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "        # Initialize embeddings\n",
    "        nn.init.xavier_uniform_(self.user_embed.weight)\n",
    "        nn.init.xavier_uniform_(self.movie_embed.weight)\n",
    "        \n",
    "    def forward(self, edge_index, user_idx, movie_idx):\n",
    "        # Get initial embeddings\n",
    "        user_embs = self.user_embed.weight\n",
    "        movie_embs = self.movie_embed.weight\n",
    "        all_embs = torch.cat([user_embs, movie_embs], dim=0)\n",
    "        \n",
    "        # Store embeddings for each layer\n",
    "        embs_list = [all_embs]\n",
    "        \n",
    "        # Propagate through graph layers\n",
    "        for _ in range(self.num_layers):\n",
    "            all_embs = self.propagate(edge_index, all_embs)\n",
    "            embs_list.append(all_embs)\n",
    "        \n",
    "        # Weighted sum of embeddings across layers (LightGCN style)\n",
    "        final_embs = torch.stack(embs_list, dim=0)\n",
    "        weighted_embs = torch.sum(\n",
    "            self.layer_weights.unsqueeze(1).unsqueeze(2) * final_embs, \n",
    "            dim=0\n",
    "        )\n",
    "        \n",
    "        # Get user and movie representations\n",
    "        user_repr = weighted_embs[user_idx]\n",
    "        movie_repr = weighted_embs[movie_idx + self.num_users]\n",
    "        \n",
    "        # Concatenate and predict rating\n",
    "        rating_input = torch.cat([user_repr, movie_repr], dim=1)\n",
    "        rating = self.rating_predictor(rating_input).squeeze()\n",
    "        \n",
    "        # Scale rating to [1, 5] range\n",
    "        rating = torch.sigmoid(rating) * 4 + 1\n",
    "        \n",
    "        return rating\n",
    "    \n",
    "    def propagate(self, edge_index, x):\n",
    "        row, col = edge_index\n",
    "        deg = torch_scatter.scatter_add(torch.ones_like(row), row, dim=0, dim_size=x.size(0))\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        out = torch_scatter.scatter_add(x[col] * norm.unsqueeze(1), row, dim=0, dim_size=x.size(0))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e499c7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model architectures defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# GRAPHREC MODEL\n",
    "\n",
    "class GraphRec(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, dropout=0.3):\n",
    "        super().__init__()\n",
    "        # Project input features\n",
    "        self.input_projection = (torch.nn.Linear(input_dim, hidden_dim) \n",
    "                                if input_dim != hidden_dim \n",
    "                                else torch.nn.Identity())\n",
    "        \n",
    "        # Graph convolutional layers\n",
    "        self.conv1 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        # Rating predictor\n",
    "        self.rating_predictor = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim * 2, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            \n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            \n",
    "            torch.nn.Linear(32, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout/2),\n",
    "            \n",
    "            torch.nn.Linear(16, 1)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    torch.nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x, edge_index, user_idx, movie_idx):\n",
    "        # Project input features\n",
    "        h = self.input_projection(x)\n",
    "        \n",
    "        # Apply GNN layers\n",
    "        h = self.conv1(h, edge_index)\n",
    "        h = self.bn1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.dropout(h)\n",
    "        \n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = self.bn2(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.dropout(h)\n",
    "        \n",
    "        # Get user and movie representations\n",
    "        user_repr = h[user_idx]\n",
    "        movie_repr = h[movie_idx]\n",
    "        \n",
    "        # Predict rating\n",
    "        rating_input = torch.cat([user_repr, movie_repr], dim=1)\n",
    "        return self.rating_predictor(rating_input).squeeze()\n",
    "\n",
    "print(\"✓ Model architectures defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9f3122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINING graph loaded\n",
      "  Users: 15,000\n",
      "  Movies: 5,979\n",
      "  Edges: 5,219,794\n",
      "  Node features: torch.Size([20979, 64])\n",
      "\n",
      "This graph will be used to compute embeddings for VALIDATION predictions\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed TRAINING data (graph structure built from training set)\n",
    "preprocessed_data_path = '../models/preprocessed_data.pt'\n",
    "preprocessed_data = torch.load(preprocessed_data_path, weights_only=False)\n",
    "\n",
    "data = preprocessed_data['data']\n",
    "user_mapping = preprocessed_data['user_mapping']  # user_id -> index (from TRAINING)\n",
    "movie_mapping = preprocessed_data['movie_mapping']  # movie_id -> index (from TRAINING)\n",
    "\n",
    "# This is the TRAINING graph structure\n",
    "x = data.x.to(device)  # Node features from TRAINING\n",
    "edge_index = data.edge_index.to(device)  # Graph edges from TRAINING interactions\n",
    "\n",
    "num_users = len(user_mapping)\n",
    "num_movies = len(movie_mapping)\n",
    "\n",
    "print(f\"✓ TRAINING graph loaded\")\n",
    "print(f\"  Users: {num_users:,}\")\n",
    "print(f\"  Movies: {num_movies:,}\")\n",
    "print(f\"  Edges: {edge_index.shape[1]:,}\")\n",
    "print(f\"  Node features: {x.shape}\")\n",
    "print(f\"\\nThis graph will be used to compute embeddings for VALIDATION predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ffd9848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Matrix Factorization model...\n",
      "✓ MF model loaded\n",
      "  Parameters: 1,342,656\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Matrix Factorization model...\")\n",
    "\n",
    "# Load checkpoint\n",
    "mf_checkpoint = torch.load('../models/best_mf_model.pth', weights_only=False)\n",
    "\n",
    "# Initialize model\n",
    "mf_model = MatrixFactorization(\n",
    "    num_users=num_users,\n",
    "    num_movies=num_movies,\n",
    "    embed_dim=64,\n",
    "    dropout_rate=0.2  # Match your training config\n",
    ")\n",
    "\n",
    "# Load the state dict directly since checkpoint is just the state_dict\n",
    "mf_model.load_state_dict(mf_checkpoint)\n",
    "mf_model = mf_model.to(device)\n",
    "mf_model.eval()\n",
    "\n",
    "print(f\"✓ MF model loaded\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in mf_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88348dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in LightGCN checkpoint: ['layer_weights', 'user_embed.weight', 'movie_embed.weight', 'rating_predictor.0.weight', 'rating_predictor.0.bias', 'rating_predictor.3.weight', 'rating_predictor.3.bias', 'rating_predictor.5.weight', 'rating_predictor.5.bias']\n",
      "Type of checkpoint: <class 'collections.OrderedDict'>\n",
      "✓ LightGCN model loaded\n",
      "  Parameters: 1,367,493\n"
     ]
    }
   ],
   "source": [
    "# First, check the LightGCN checkpoint structure\n",
    "lgcn_checkpoint = torch.load('../models/best_rating_lightgcn_model.pth', weights_only=False)\n",
    "print(\"Keys in LightGCN checkpoint:\", list(lgcn_checkpoint.keys()))\n",
    "print(\"Type of checkpoint:\", type(lgcn_checkpoint))\n",
    "\n",
    "# Initialize model\n",
    "lgcn_model = LightGCN_Rating(\n",
    "    num_users=num_users,\n",
    "    num_movies=num_movies,\n",
    "    embed_dim=64,\n",
    "    num_layers=3  # Match your training config\n",
    ")\n",
    "\n",
    "# Load based on the structure\n",
    "lgcn_checkpoint = torch.load('../models/best_rating_lightgcn_model.pth', weights_only=False)\n",
    "lgcn_model.load_state_dict(lgcn_checkpoint)\n",
    "lgcn_model = lgcn_model.to(device)\n",
    "lgcn_model.eval()\n",
    "\n",
    "print(f\"✓ LightGCN model loaded\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in lgcn_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe301795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in GraphRec checkpoint: ['conv1.bias', 'conv1.lin.weight', 'conv2.bias', 'conv2.lin.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn2.num_batches_tracked', 'rating_predictor.0.weight', 'rating_predictor.0.bias', 'rating_predictor.1.weight', 'rating_predictor.1.bias', 'rating_predictor.1.running_mean', 'rating_predictor.1.running_var', 'rating_predictor.1.num_batches_tracked', 'rating_predictor.4.weight', 'rating_predictor.4.bias', 'rating_predictor.5.weight', 'rating_predictor.5.bias', 'rating_predictor.5.running_mean', 'rating_predictor.5.running_var', 'rating_predictor.5.num_batches_tracked', 'rating_predictor.8.weight', 'rating_predictor.8.bias', 'rating_predictor.11.weight', 'rating_predictor.11.bias']\n",
      "Type of checkpoint: <class 'collections.OrderedDict'>\n",
      "✓ GraphRec model loaded\n",
      "  Parameters: 19,649\n",
      "ALL MODELS LOADED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "# First, check the GraphRec checkpoint structure\n",
    "gr_checkpoint = torch.load('../models/best_graphrec_model.pth', weights_only=False)\n",
    "print(\"Keys in GraphRec checkpoint:\", list(gr_checkpoint.keys()))\n",
    "print(\"Type of checkpoint:\", type(gr_checkpoint))\n",
    "\n",
    "# Initialize model\n",
    "gr_model = GraphRec(\n",
    "    input_dim=64,  # Match your training config\n",
    "    hidden_dim=64,\n",
    "    dropout=0.3\n",
    ")\n",
    "\n",
    "# Load based on the structure\n",
    "gr_checkpoint = torch.load('../models/best_graphrec_model.pth', weights_only=False)\n",
    "gr_model.load_state_dict(gr_checkpoint)\n",
    "gr_model = gr_model.to(device)\n",
    "gr_model.eval()\n",
    "\n",
    "print(f\"✓ GraphRec model loaded\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in gr_model.parameters()):,}\")\n",
    "\n",
    "\n",
    "print(\"ALL MODELS LOADED SUCCESSFULLY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7c1961f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original VALIDATION set size: 260,990\n",
      "These are unseen user-item pairs we want to predict ratings for.\n",
      "\n",
      "Common VALIDATION set size: 260,990\n",
      "Filtered out: 0 pairs\n",
      "(Filtered pairs contain users/items NOT in training graph)\n",
      "\n",
      "✓ Common validation set created successfully!\n",
      "\n",
      "Sample validation pairs:\n",
      "   userId  movieId  rating  user_idx  movie_idx\n",
      "0  141084    56367     4.5      6357       1296\n",
      "1  324282     1385     4.5     14675       1715\n",
      "2   31676     1193     3.5      1336        147\n",
      "3  233914     1945     5.0     10539       1582\n",
      "4  155789      942     3.5      6992       4065\n"
     ]
    }
   ],
   "source": [
    "# Load VALIDATION data (these are user-item pairs NOT in training)\n",
    "validation_df = pd.read_csv('../data/external/val_split.csv')\n",
    "\n",
    "print(f\"Original VALIDATION set size: {len(validation_df):,}\")\n",
    "print(\"These are unseen user-item pairs we want to predict ratings for.\\n\")\n",
    "\n",
    "# Filter to only users and items that EXIST in the TRAINING graph\n",
    "valid_users = validation_df['userId'].isin(user_mapping.keys())\n",
    "valid_movies = validation_df['movieId'].isin(movie_mapping.keys())\n",
    "\n",
    "common_val_df = validation_df[valid_users & valid_movies].copy()\n",
    "\n",
    "print(f\"Common VALIDATION set size: {len(common_val_df):,}\")\n",
    "print(f\"Filtered out: {len(validation_df) - len(common_val_df):,} pairs\")\n",
    "print(\"(Filtered pairs contain users/items NOT in training graph)\")\n",
    "\n",
    "# Map validation user/item IDs to TRAINING indices\n",
    "common_val_df['user_idx'] = common_val_df['userId'].map(user_mapping)\n",
    "common_val_df['movie_idx'] = common_val_df['movieId'].map(movie_mapping)\n",
    "\n",
    "# Verify all mappings succeeded\n",
    "assert common_val_df['user_idx'].notna().all(), \"Some user indices are missing\"\n",
    "assert common_val_df['movie_idx'].notna().all(), \"Some movie indices are missing\"\n",
    "\n",
    "print(\"\\n✓ Common validation set created successfully!\")\n",
    "print(\"\\nSample validation pairs:\")\n",
    "print(common_val_df[['userId', 'movieId', 'rating', 'user_idx', 'movie_idx']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2d24004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING PREDICTIONS ON VALIDATION SET\n",
      "\n",
      "1. Matrix Factorization predictions...\n",
      "   RMSE: 0.7818\n",
      "   MAE:  0.5950\n",
      "   Predictions shape: (260990,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"GENERATING PREDICTIONS ON VALIDATION SET\")\n",
    "\n",
    "print(\"\\n1. Matrix Factorization predictions...\")\n",
    "\n",
    "# These are VALIDATION user-item pairs (not in training)\n",
    "user_indices = torch.tensor(common_val_df['user_idx'].values, \n",
    "                            dtype=torch.long, device=device)\n",
    "item_indices = torch.tensor(common_val_df['movie_idx'].values, \n",
    "                            dtype=torch.long, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # MF predicts ratings for VALIDATION pairs using learned embeddings\n",
    "    mf_predictions = mf_model(user_indices, item_indices).cpu().numpy()\n",
    "\n",
    "# Calculate RMSE on VALIDATION set\n",
    "true_ratings = common_val_df['rating'].values\n",
    "mf_rmse = np.sqrt(mean_squared_error(true_ratings, mf_predictions))\n",
    "mf_mae = np.mean(np.abs(true_ratings - mf_predictions))\n",
    "\n",
    "print(f\"   RMSE: {mf_rmse:.4f}\")\n",
    "print(f\"   MAE:  {mf_mae:.4f}\")\n",
    "print(f\"   Predictions shape: {mf_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93d8d4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. LightGCN predictions...\n",
      "   RMSE: 0.8102\n",
      "   MAE:  0.6141\n",
      "   Predictions shape: (260990,)\n",
      "   Note: Used TRAINING edge_index for graph convolutions\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. LightGCN predictions...\")\n",
    "\n",
    "user_indices = torch.tensor(common_val_df['user_idx'].values, \n",
    "                            dtype=torch.long, device=device)\n",
    "item_indices = torch.tensor(common_val_df['movie_idx'].values, \n",
    "                            dtype=torch.long, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # LightGCN uses TRAINING edge_index to compute embeddings\n",
    "    # Then predicts ratings for VALIDATION user-item pairs\n",
    "    lgcn_predictions = lgcn_model(edge_index, user_indices, item_indices).cpu().numpy()\n",
    "\n",
    "# Calculate RMSE on VALIDATION set\n",
    "lgcn_rmse = np.sqrt(mean_squared_error(true_ratings, lgcn_predictions))\n",
    "lgcn_mae = np.mean(np.abs(true_ratings - lgcn_predictions))\n",
    "\n",
    "print(f\"   RMSE: {lgcn_rmse:.4f}\")\n",
    "print(f\"   MAE:  {lgcn_mae:.4f}\")\n",
    "print(f\"   Predictions shape: {lgcn_predictions.shape}\")\n",
    "print(f\"   Note: Used TRAINING edge_index for graph convolutions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f05c1c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. GraphRec predictions...\n",
      "   RMSE: 1.3058\n",
      "   MAE:  1.0937\n",
      "   Predictions shape: (260990,)\n",
      "   Note: Used TRAINING x and edge_index for GCN layers\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3. GraphRec predictions...\")\n",
    "\n",
    "user_indices = torch.tensor(common_val_df['user_idx'].values, \n",
    "                            dtype=torch.long, device=device)\n",
    "\n",
    "# GraphRec expects movie indices OFFSET by num_users\n",
    "movie_indices = torch.tensor(common_val_df['movie_idx'].values + num_users, \n",
    "                             dtype=torch.long, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # GraphRec uses TRAINING x and edge_index to compute embeddings\n",
    "    # Then predicts ratings for VALIDATION user-item pairs\n",
    "    gr_predictions = gr_model(x, edge_index, user_indices, movie_indices).cpu().numpy()\n",
    "\n",
    "# Calculate RMSE on VALIDATION set\n",
    "gr_rmse = np.sqrt(mean_squared_error(true_ratings, gr_predictions))\n",
    "gr_mae = np.mean(np.abs(true_ratings - gr_predictions))\n",
    "\n",
    "print(f\"   RMSE: {gr_rmse:.4f}\")\n",
    "print(f\"   MAE:  {gr_mae:.4f}\")\n",
    "print(f\"   Predictions shape: {gr_predictions.shape}\")\n",
    "print(f\"   Note: Used TRAINING x and edge_index for GCN layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "783491ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDIVIDUAL MODEL PERFORMANCE ON VALIDATION SET\n",
      "\n",
      "               Model     RMSE      MAE\n",
      "Matrix Factorization 0.781759 0.594995\n",
      "            LightGCN 0.810176 0.614109\n",
      "            GraphRec 1.305842 1.093661\n",
      "\n",
      "✓ Best single model: Matrix Factorization\n",
      "✓ Best RMSE: 0.7818\n",
      "\n",
      "All predictions made on 260,990 VALIDATION pairs\n"
     ]
    }
   ],
   "source": [
    "print(\"INDIVIDUAL MODEL PERFORMANCE ON VALIDATION SET\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Matrix Factorization', 'LightGCN', 'GraphRec'],\n",
    "    'RMSE': [mf_rmse, lgcn_rmse, gr_rmse],\n",
    "    'MAE': [mf_mae, lgcn_mae, gr_mae]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + results_df.to_string(index=False))\n",
    "print(f\"\\n✓ Best single model: {results_df.loc[results_df['RMSE'].idxmin(), 'Model']}\")\n",
    "print(f\"✓ Best RMSE: {results_df['RMSE'].min():.4f}\")\n",
    "print(f\"\\nAll predictions made on {len(common_val_df):,} VALIDATION pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd69c2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ VALIDATION predictions saved to ../predictions/ensemble_predictions.pt\n"
     ]
    }
   ],
   "source": [
    "# Save all predictions made on VALIDATION set\n",
    "predictions_dict = {\n",
    "    'mf_predictions': mf_predictions,\n",
    "    'lightgcn_predictions': lgcn_predictions,\n",
    "    'graphrec_predictions': gr_predictions,\n",
    "    'true_ratings': true_ratings,\n",
    "    'validation_data': common_val_df[['userId', 'movieId', 'rating', \n",
    "                                      'user_idx', 'movie_idx']].copy(),\n",
    "    'info': {\n",
    "        'description': 'Predictions on VALIDATION set using models trained on TRAINING set',\n",
    "        'num_validation_samples': len(common_val_df),\n",
    "        'num_training_users': num_users,\n",
    "        'num_training_movies': num_movies,\n",
    "        'training_edges': edge_index.shape[1]\n",
    "    }\n",
    "}\n",
    "\n",
    "output_path = '../predictions/ensemble_predictions.pt'\n",
    "torch.save(predictions_dict, output_path)\n",
    "print(f\"✓ VALIDATION predictions saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a20afbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMIZING ENSEMBLE WEIGHTS ON VALIDATION SET\n",
      "Optimizing weights...\n",
      "\n",
      "✓ Optimization Complete!\n",
      "\n",
      "Optimal weights:\n",
      "  MF:       0.9460\n",
      "  LightGCN: 0.0540\n",
      "  GraphRec: 0.0000\n",
      "\n",
      "Ensemble RMSE on VALIDATION: 0.7817\n",
      "\n",
      "Best single model RMSE: 0.7818\n",
      "Ensemble improvement: 0.0001 (0.01%)\n",
      "✓ Ensemble is better by 0.0001 RMSE points!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"OPTIMIZING ENSEMBLE WEIGHTS ON VALIDATION SET\")\n",
    "\n",
    "# Objective function: minimize RMSE on VALIDATION set\n",
    "def ensemble_rmse(weights):\n",
    "    w_mf, w_lgcn, w_gr = weights\n",
    "    ensemble_preds = (w_mf * mf_predictions + \n",
    "                     w_lgcn * lgcn_predictions + \n",
    "                     w_gr * gr_predictions)\n",
    "    return np.sqrt(mean_squared_error(true_ratings, ensemble_preds))\n",
    "\n",
    "# Constraints: weights sum to 1 and are non-negative\n",
    "constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "bounds = [(0, 1), (0, 1), (0, 1)]\n",
    "\n",
    "# Initial guess: equal weights\n",
    "initial_weights = [1/3, 1/3, 1/3]\n",
    "\n",
    "print(\"Optimizing weights...\")\n",
    "# Optimize\n",
    "result = minimize(\n",
    "    ensemble_rmse,\n",
    "    initial_weights,\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "optimal_weights = result.x\n",
    "optimal_rmse = result.fun\n",
    "\n",
    "print(\"\\n✓ Optimization Complete!\")\n",
    "print(f\"\\nOptimal weights:\")\n",
    "print(f\"  MF:       {optimal_weights[0]:.4f}\")\n",
    "print(f\"  LightGCN: {optimal_weights[1]:.4f}\")\n",
    "print(f\"  GraphRec: {optimal_weights[2]:.4f}\")\n",
    "print(f\"\\nEnsemble RMSE on VALIDATION: {optimal_rmse:.4f}\")\n",
    "\n",
    "# Calculate improvement\n",
    "best_single_rmse = min(mf_rmse, lgcn_rmse, gr_rmse)\n",
    "improvement = best_single_rmse - optimal_rmse\n",
    "improvement_pct = (improvement / best_single_rmse) * 100\n",
    "\n",
    "print(f\"\\nBest single model RMSE: {best_single_rmse:.4f}\")\n",
    "print(f\"Ensemble improvement: {improvement:.4f} ({improvement_pct:.2f}%)\")\n",
    "\n",
    "if improvement > 0:\n",
    "    print(f\"✓ Ensemble is better by {improvement:.4f} RMSE points!\")\n",
    "else:\n",
    "    print(f\"⚠ Ensemble not better than best single model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e046f03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction correlations:\n",
      "MF vs LightGCN: 0.9421318200336354\n",
      "MF vs GraphRec: 0.16254633358231846\n",
      "LightGCN vs GraphRec: 0.1659962180258239\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "correlation_matrix = np.corrcoef([mf_predictions, lgcn_predictions, gr_predictions])\n",
    "print(\"Prediction correlations:\")\n",
    "print(\"MF vs LightGCN:\", correlation_matrix[0,1])\n",
    "print(\"MF vs GraphRec:\", correlation_matrix[0,2])\n",
    "print(\"LightGCN vs GraphRec:\", correlation_matrix[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c0887f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Optimal weights saved to ../models/ensemble_weights.pt\n"
     ]
    }
   ],
   "source": [
    "# Save optimal weights for future use\n",
    "weights_dict = {\n",
    "    'optimal_weights': optimal_weights,\n",
    "    'ensemble_rmse': optimal_rmse,\n",
    "    'individual_rmses': {\n",
    "        'MF': mf_rmse,\n",
    "        'LightGCN': lgcn_rmse,\n",
    "        'GraphRec': gr_rmse\n",
    "    },\n",
    "    'individual_maes': {\n",
    "        'MF': mf_mae,\n",
    "        'LightGCN': lgcn_mae,\n",
    "        'GraphRec': gr_mae\n",
    "    },\n",
    "    'info': {\n",
    "        'optimized_on': 'validation_set',\n",
    "        'num_samples': len(common_val_df)\n",
    "    }\n",
    "}\n",
    "\n",
    "weights_path = '../models/ensemble_weights.pt'\n",
    "torch.save(weights_dict, weights_path)\n",
    "print(f\"✓ Optimal weights saved to {weights_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7ebd7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ensemble prediction function defined!\n",
      "\n",
      "This function can predict on ANY new pairs\n",
      "(as long as users/items exist in the TRAINING graph)\n"
     ]
    }
   ],
   "source": [
    "def ensemble_predict(user_ids, movie_ids, optimal_weights):\n",
    "    \"\"\"\n",
    "    Generate ensemble predictions for NEW user-movie pairs.\n",
    "    \n",
    "    Args:\n",
    "        user_ids: List of original user IDs (must be in training)\n",
    "        movie_ids: List of original movie IDs (must be in training)\n",
    "        optimal_weights: Array of [w_mf, w_lgcn, w_gr]\n",
    "    \n",
    "    Returns:\n",
    "        ensemble_preds: Array of ensemble predictions\n",
    "        individual_preds: Dict with predictions from each model\n",
    "    \"\"\"\n",
    "    # Verify all IDs exist in training\n",
    "    for uid in user_ids:\n",
    "        if uid not in user_mapping:\n",
    "            raise ValueError(f\"User ID {uid} not in training data\")\n",
    "    for mid in movie_ids:\n",
    "        if mid not in movie_mapping:\n",
    "            raise ValueError(f\"Movie ID {mid} not in training data\")\n",
    "    \n",
    "    # Map to TRAINING indices\n",
    "    user_indices_list = [user_mapping[uid] for uid in user_ids]\n",
    "    movie_indices_list = [movie_mapping[mid] for mid in movie_ids]\n",
    "    \n",
    "    user_tensor = torch.tensor(user_indices_list, dtype=torch.long, device=device)\n",
    "    movie_tensor = torch.tensor(movie_indices_list, dtype=torch.long, device=device)\n",
    "    \n",
    "    # Get predictions from each model using TRAINING graph\n",
    "    with torch.no_grad():\n",
    "        # MF predictions\n",
    "        mf_preds = mf_model(user_tensor, movie_tensor).cpu().numpy()\n",
    "        \n",
    "        # LightGCN predictions (uses TRAINING edge_index)\n",
    "        lgcn_preds = lgcn_model(edge_index, user_tensor, movie_tensor).cpu().numpy()\n",
    "        \n",
    "        # GraphRec predictions (uses TRAINING x and edge_index)\n",
    "        movie_tensor_gr = torch.tensor(\n",
    "            [idx + num_users for idx in movie_indices_list],\n",
    "            dtype=torch.long, \n",
    "            device=device\n",
    "        )\n",
    "        gr_preds = gr_model(x, edge_index, user_tensor, movie_tensor_gr).cpu().numpy()\n",
    "    \n",
    "    # Combine predictions using optimal weights\n",
    "    w_mf, w_lgcn, w_gr = optimal_weights\n",
    "    ensemble_preds = w_mf * mf_preds + w_lgcn * lgcn_preds + w_gr * gr_preds\n",
    "    \n",
    "    return ensemble_preds, {\n",
    "        'mf': mf_preds,\n",
    "        'lightgcn': lgcn_preds,\n",
    "        'graphrec': gr_preds\n",
    "    }\n",
    "\n",
    "print(\"✓ Ensemble prediction function defined!\")\n",
    "print(\"\\nThis function can predict on ANY new pairs\")\n",
    "print(\"(as long as users/items exist in the TRAINING graph)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0b20d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ENSEMBLE ON SAMPLE VALIDATION PAIRS\n",
      "\n",
      "Testing on 5 random validation pairs...\n",
      "\n",
      "Detailed Predictions:\n",
      "\n",
      "User 164541, Movie 2706 → True: 4.0\n",
      "  MF:       3.191 (error: 0.809)\n",
      "  LightGCN: 3.313 (error: 0.687)\n",
      "  GraphRec: 2.517 (error: 1.483)\n",
      "  Ensemble: 3.197 (error: 0.803) ★\n",
      "\n",
      "User 330707, Movie 2011 → True: 3.5\n",
      "  MF:       3.715 (error: 0.215)\n",
      "  LightGCN: 3.678 (error: 0.178)\n",
      "  GraphRec: 2.441 (error: 1.059)\n",
      "  Ensemble: 3.713 (error: 0.213) ★\n",
      "\n",
      "User 296688, Movie 7285 → True: 2.5\n",
      "  MF:       3.531 (error: 1.031)\n",
      "  LightGCN: 3.617 (error: 1.117)\n",
      "  GraphRec: 3.266 (error: 0.766)\n",
      "  Ensemble: 3.535 (error: 1.035) ★\n",
      "\n",
      "User 218572, Movie 274971 → True: 3.5\n",
      "  MF:       3.354 (error: 0.146)\n",
      "  LightGCN: 3.390 (error: 0.110)\n",
      "  GraphRec: 3.147 (error: 0.353)\n",
      "  Ensemble: 3.356 (error: 0.144) ★\n",
      "\n",
      "User 305823, Movie 49647 → True: 2.0\n",
      "  MF:       2.206 (error: 0.206)\n",
      "  LightGCN: 1.926 (error: 0.074)\n",
      "  GraphRec: 3.315 (error: 1.315)\n",
      "  Ensemble: 2.191 (error: 0.191) ★\n",
      "\n",
      "Sample MAE: 0.4773\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING ENSEMBLE ON SAMPLE VALIDATION PAIRS\")\n",
    "\n",
    "\n",
    "# Take 5 random validation pairs\n",
    "sample_indices = np.random.choice(len(common_val_df), size=5, replace=False)\n",
    "test_user_ids = common_val_df['userId'].iloc[sample_indices].tolist()\n",
    "test_movie_ids = common_val_df['movieId'].iloc[sample_indices].tolist()\n",
    "test_true_ratings = common_val_df['rating'].iloc[sample_indices].tolist()\n",
    "\n",
    "print(f\"\\nTesting on 5 random validation pairs...\")\n",
    "\n",
    "ensemble_preds, individual_preds = ensemble_predict(\n",
    "    test_user_ids, \n",
    "    test_movie_ids, \n",
    "    optimal_weights\n",
    ")\n",
    "\n",
    "print(\"\\nDetailed Predictions:\")\n",
    "\n",
    "for i in range(len(test_user_ids)):\n",
    "    true_rating = test_true_ratings[i]\n",
    "    print(f\"\\nUser {test_user_ids[i]}, Movie {test_movie_ids[i]} → True: {true_rating:.1f}\")\n",
    "    print(f\"  MF:       {individual_preds['mf'][i]:.3f} (error: {abs(true_rating - individual_preds['mf'][i]):.3f})\")\n",
    "    print(f\"  LightGCN: {individual_preds['lightgcn'][i]:.3f} (error: {abs(true_rating - individual_preds['lightgcn'][i]):.3f})\")\n",
    "    print(f\"  GraphRec: {individual_preds['graphrec'][i]:.3f} (error: {abs(true_rating - individual_preds['graphrec'][i]):.3f})\")\n",
    "    print(f\"  Ensemble: {ensemble_preds[i]:.3f} (error: {abs(true_rating - ensemble_preds[i]):.3f}) ★\")\n",
    "\n",
    "# Calculate mean absolute error for this sample\n",
    "sample_mae = np.mean([abs(test_true_ratings[i] - ensemble_preds[i]) for i in range(len(test_user_ids))])\n",
    "print(f\"\\nSample MAE: {sample_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015b6376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
